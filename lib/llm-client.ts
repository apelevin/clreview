import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';

// –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
let openaiInstance: OpenAI | null = null;

function getOpenAIClient(): OpenAI {
  if (!openaiInstance) {
    // –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –Ω–∞ Vercel
    const envInfo = {
      VERCEL: process.env.VERCEL,
      NODE_ENV: process.env.NODE_ENV,
      VERCEL_ENV: process.env.VERCEL_ENV,
      hasApiKey: !!process.env.OPENROUTER_API_KEY,
      apiKeyLength: process.env.OPENROUTER_API_KEY?.length || 0,
    };
    
    if (!process.env.OPENROUTER_API_KEY) {
      console.error('OPENROUTER_API_KEY –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–∫—Ä—É–∂–µ–Ω–∏–∏:', envInfo);
      const isVercel = process.env.VERCEL || process.env.NODE_ENV === 'production';
      const errorMessage = isVercel
        ? `OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è Vercel. –î–æ–±–∞–≤—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞: Settings ‚Üí Environment Variables. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –¥–ª—è –æ–∫—Ä—É–∂–µ–Ω–∏—è "${process.env.VERCEL_ENV || 'Production'}" –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –¥–µ–ø–ª–æ–π.`
        : 'OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env.local –∏ –¥–æ–±–∞–≤—å—Ç–µ OPENROUTER_API_KEY=your_key';
      throw new Error(errorMessage);
    }
    
    // –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é (–±–µ–∑ –∫–ª—é—á–∞)
    console.log('OpenRouter –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –û–∫—Ä—É–∂–µ–Ω–∏–µ:', {
      VERCEL: process.env.VERCEL,
      VERCEL_ENV: process.env.VERCEL_ENV,
      NODE_ENV: process.env.NODE_ENV,
    });
    
    openaiInstance = new OpenAI({
      baseURL: 'https://openrouter.ai/api/v1',
      apiKey: process.env.OPENROUTER_API_KEY,
      defaultHeaders: {
        'HTTP-Referer': process.env.OPENROUTER_HTTP_REFERER || 'https://github.com/apelevin/review',
        'X-Title': 'Legal Review Service',
      },
    });
  }
  return openaiInstance;
}

// –¶–µ–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π (per 1M tokens)
interface ModelPricing {
  input: number;
  cached_input: number;
  output: number;
}

// –¶–µ–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π OpenRouter (–∑–∞ —Ç–æ–∫–µ–Ω, –Ω–µ –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤!)
// –¶–µ–Ω—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ OpenRouter API
// –í–Ω–∏–º–∞–Ω–∏–µ: OpenRouter –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–µ–Ω—ã –∑–∞ —Ç–æ–∫–µ–Ω, –ø–æ—ç—Ç–æ–º—É —É–º–Ω–æ–∂–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
const MODEL_PRICING: Record<string, ModelPricing> = {
  // Step 0: xAI Grok 4.1 Fast (–¥–∞–Ω–Ω—ã–µ –∏–∑ OpenRouter API)
  'x-ai/grok-4.1-fast': {
    input: 0.0000002, // $0.0000002 –∑–∞ —Ç–æ–∫–µ–Ω
    cached_input: 0.00000002, // $0.00000002 –∑–∞ —Ç–æ–∫–µ–Ω
    output: 0.0000005, // $0.0000005 –∑–∞ —Ç–æ–∫–µ–Ω
  },
  // Step 1: Google Gemini 2.5 Flash Lite Preview (–¥–∞–Ω–Ω—ã–µ –∏–∑ OpenRouter API)
  'google/gemini-2.5-flash-lite-preview-09-2025': {
    input: 0.0000001, // $0.0000001 –∑–∞ —Ç–æ–∫–µ–Ω
    cached_input: 0.00000001, // $0.00000001 –∑–∞ —Ç–æ–∫–µ–Ω
    output: 0.0000004, // $0.0000004 –∑–∞ —Ç–æ–∫–µ–Ω
  },
  // Step 3: DeepSeek V3.2 (–¥–∞–Ω–Ω—ã–µ –∏–∑ OpenRouter API)
  'deepseek/deepseek-v3.2': {
    input: 0.00000026, // $0.00000026 –∑–∞ —Ç–æ–∫–µ–Ω (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Å 0.00000027)
    cached_input: 0.000000026, // $0.000000026 –∑–∞ —Ç–æ–∫–µ–Ω
    output: 0.00000039, // $0.00000039 –∑–∞ —Ç–æ–∫–µ–Ω (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Å 0.00000041)
  },
  // Step 4: Google Gemini 2.5 Flash Preview (–¥–∞–Ω–Ω—ã–µ –∏–∑ OpenRouter API)
  'google/gemini-2.5-flash-preview-09-2025': {
    input: 0.0000003, // $0.0000003 –∑–∞ —Ç–æ–∫–µ–Ω
    cached_input: 0.00000003, // $0.00000003 –∑–∞ —Ç–æ–∫–µ–Ω
    output: 0.0000025, // $0.0000025 –∑–∞ —Ç–æ–∫–µ–Ω
  },
  // –°—Ç–∞—Ä—ã–µ –º–æ–¥–µ–ª–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏) - —Ü–µ–Ω—ã –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤, –Ω—É–∂–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
  'openai/gpt-5-mini': {
    input: 0.25 / 1_000_000, // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ $0.25 / 1M tokens
    cached_input: 0.025 / 1_000_000,
    output: 2.0 / 1_000_000,
  },
  'openai/gpt-5': {
    input: 1.25 / 1_000_000, // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ $1.25 / 1M tokens
    cached_input: 0.125 / 1_000_000,
    output: 10.0 / 1_000_000,
  },
  'openai/gpt-5.1': {
    input: 1.25 / 1_000_000, // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ $1.25 / 1M tokens
    cached_input: 0.125 / 1_000_000,
    output: 10.0 / 1_000_000,
  },
};

export interface TokenUsage {
  promptTokens: number;
  completionTokens: number;
  cachedTokens?: number;
  totalTokens: number;
}

export interface CostBreakdown {
  inputCost: number;
  cachedInputCost: number;
  outputCost: number;
  totalCost: number;
}

export interface APIResponse {
  content: string;
  usage: TokenUsage;
  cost: CostBreakdown;
}


/**
 * –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenRouter API —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
 * @param systemPrompt - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
 * @param userContent - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞)
 * @param model - –º–æ–¥–µ–ª—å OpenRouter (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é openai/gpt-5.1)
 * @returns Promise —Å –æ—Ç–≤–µ—Ç–æ–º –æ—Ç –º–æ–¥–µ–ª–∏, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ä–∞—Å—Ö–æ–¥–∞–º–∏
 */
export async function callOpenAI(
  systemPrompt: string,
  userContent: string,
  model: string = 'openai/gpt-5.1'
): Promise<APIResponse> {
  try {
    const openai = getOpenAIClient();
    
    let response;
    let usedModel = model;
    
    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
    const createRequest = () => {
      return openai.chat.completions.create({
        model: usedModel,
        messages: [
          {
            role: 'system',
            content: systemPrompt,
          },
          {
            role: 'user',
            content: userContent,
          },
        ],
        temperature: 0.7,
      });
    };
    
    // –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
    response = await createRequest();

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç OpenRouter API');
    }

    // –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
    const usage = response.usage;
    if (!usage) {
      throw new Error('–ù–µ –ø–æ–ª—É—á–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤');
    }

    const tokenUsage: TokenUsage = {
      promptTokens: usage.prompt_tokens || 0,
      completionTokens: usage.completion_tokens || 0,
      cachedTokens: (usage as any).cached_tokens || 0,
      totalTokens: usage.total_tokens || 0,
    };

    // –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞—Å—Ö–æ–¥—ã
    const inputTokens = tokenUsage.promptTokens - (tokenUsage.cachedTokens || 0);
    const cachedInputTokens = tokenUsage.cachedTokens || 0;
    const outputTokens = tokenUsage.completionTokens;

    // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
    const pricing = MODEL_PRICING[usedModel] || MODEL_PRICING['x-ai/grok-4.1-fast'];

    // –¶–µ–Ω—ã –≤ OpenRouter API —É–∫–∞–∑–∞–Ω—ã –∑–∞ —Ç–æ–∫–µ–Ω, –∞ –Ω–µ –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤
    const cost: CostBreakdown = {
      inputCost: inputTokens * pricing.input,
      cachedInputCost: cachedInputTokens * pricing.cached_input,
      outputCost: outputTokens * pricing.output,
      totalCost: 0,
    };

    cost.totalCost = cost.inputCost + cost.cachedInputCost + cost.outputCost;

    return {
      content,
      usage: tokenUsage,
      cost,
    };
  } catch (error) {
    throw new Error(
      `–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenRouter API: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}

/**
 * –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞
 * @param promptPath - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–æ–º
 * @returns Promise —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –ø—Ä–æ–º–ø—Ç–∞
 */
export async function loadPrompt(promptPath: string): Promise<string> {
  try {
    const fullPath = path.join(process.cwd(), promptPath);
    const content = await fs.readFile(fullPath, 'utf-8');
    return content.trim();
  } catch (error) {
    throw new Error(
      `–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ ${promptPath}: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}

/**
 * –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞ –∏ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞ SYSTEM –∏ USER —á–∞—Å—Ç–∏
 * @param promptPath - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–æ–º
 * @returns Promise —Å –æ–±—ä–µ–∫—Ç–æ–º, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º systemPrompt –∏ userPrompt
 */
export async function loadPromptWithParts(promptPath: string): Promise<{
  systemPrompt: string;
  userPrompt: string;
}> {
  try {
    const fullPath = path.join(process.cwd(), promptPath);
    const content = await fs.readFile(fullPath, 'utf-8');
    
    // –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ SYSTEM –∏ USER —á–∞—Å—Ç–∏
    const systemMatch = content.match(/## üü¶\s*\*\*SYSTEM PROMPT\*\*\s*\n\n(.*?)(?=\n---|\n## üü©|$)/s);
    const userMatch = content.match(/## üü©\s*\*\*USER PROMPT\*\*\s*\n\n(.*?)(?=\n---|\n## üü•|$)/s);
    
    const systemPrompt = systemMatch ? systemMatch[1].trim() : content.trim();
    const userPrompt = userMatch ? userMatch[1].trim() : '';
    
    return {
      systemPrompt,
      userPrompt: userPrompt || content.trim(), // –ï—Å–ª–∏ USER –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç
    };
  } catch (error) {
    throw new Error(
      `–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ ${promptPath}: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}

